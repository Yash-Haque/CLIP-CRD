{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f12AfpK7QJGU",
        "outputId": "2f7d5f03-d90c-48db-fd34-602a718f48b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from enum import Enum\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "from typing import Tuple, Optional, Union"
      ],
      "metadata": {
        "id": "HsEdGjNWY4bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/ClipCap/oscar_split_ViT-B_32_train.pkl\"\n",
        "print(file_path[:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8UbL5aSuA_K",
        "outputId": "bf9b8d40-0fc7-4464-8ae5-a8ff32c77a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ClipCap/oscar_split_ViT-B_32_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKboGBRSvLJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/ClipCap/oscar_split_ViT-B_32_train.pkl\"\n",
        "with open(file_path, 'rb') as f:\n",
        "  all_data = pickle.load(f)\n",
        "print(\"Data size is %0d\" % len(all_data['clip_embedding']))\n",
        "sys.stdout.flush()\n",
        "prefixes = all_data['clip_embedding']\n",
        "captions_raw = all_data['captions']\n",
        "img_ids = [caption['image_id'] for caption in captions_raw]\n",
        "print(img_ids[5])\n",
        "captions = [caption['caption'] for caption in captions_raw]\n",
        "print(captions[5])\n",
        "\n",
        "captions_tokens = []\n",
        "caption2embedding = []\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "\n",
        "for caption in captions_raw:\n",
        "  captions_tokens.append(torch.tensor(tokenizer.encode(caption['caption']), dtype=torch.int64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esbf2TigXj5-",
        "outputId": "d7562eff-54b4-4312-edbd-205302c0c532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size is 566747\n",
            "379340\n",
            "A vandalized stop sign and a red beetle on the road\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/oscar_split_ViT-B_32_train.pkl\"\n",
        "with open(file_path, 'rb') as f:\n",
        "  all_data = pickle.load(f)\n",
        "print(\"Data size is %0d\" % len(all_data['clip_embedding']))\n",
        "sys.stdout.flush()\n",
        "prefixes = all_data['clip_embedding']\n",
        "if prefixes is not None:\n",
        "  print(\"True\")\n",
        "else:\n",
        "  print(\"False\")\n",
        "captions_raw = all_data['captions']\n",
        "if captions_raw is not None:\n",
        "  print(\"True\")\n",
        "else:\n",
        "  print(\"False\")\n",
        "img_ids = [caption['id'] for caption in captions_raw]\n",
        "print(img_ids[5])\n",
        "actual_img_path = [caption['img'] for caption in captions_raw]\n",
        "print(actual_img_path[5])\n",
        "captions = [caption['text'] for caption in captions_raw]\n",
        "print(captions[5])\n",
        "\n",
        "captions_tokens = []\n",
        "caption2embedding = []\n",
        "gpt2_type: str = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "\n",
        "for caption in captions_raw:\n",
        "  captions_tokens.append(torch.tensor(tokenizer.encode(caption['text']), dtype=torch.int64))\n",
        "print(captions_tokens[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImX89ZeAv-XZ",
        "outputId": "2b38fdd3-ac1d-48e7-b033-dc6c977049c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size is 2483\n",
            "True\n",
            "True\n",
            "3003\n",
            "/kaggle/input/open-i-dataset/Open-I Dataset/images/3003.jpg\n",
            "No focal consolidation, pneumothorax, or pleural effusions. Stable calcified granulomas. Cardiomediastinal silhouette demonstrates mild tortuosity of the thoracic aorta and atherosclerotic calcifications of the aortic XXXX. No acute osseous abnormality identified.\n",
            "tensor([ 2949, 25397, 31941,    11, 29631,   849,   273,   897,    11,   393,\n",
            "         3339,  1523,   914, 15880,    13,   520,   540, 42302,  1431, 19468,\n",
            "          377, 16911,    13,  5172,    72, 12657,    72,   459,  1292, 41834,\n",
            "        15687, 11607,  7619,    84, 16579,   286,   262, 41899,   330,   291,\n",
            "          257,   419,    64,   290, 13366,  4951, 22902,  6210, 42302,  6637,\n",
            "          286,   262,   257,   419,   291, 27713,    55,    13,  1400, 14352,\n",
            "        28686,   325,   516, 42364,  1483,  5174,    13])\n"
          ]
        }
      ]
    }
  ]
}